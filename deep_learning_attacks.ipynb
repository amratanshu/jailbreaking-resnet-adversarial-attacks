{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6631eda8",
   "metadata": {},
   "source": [
    "# Deep Learning Project: Adversarial Attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f8b6c2",
   "metadata": {},
   "source": [
    "This notebook implements and evaluates adversarial attacks (FGSM, PGD) on a ResNet-34 model using a subset of ImageNet. It is converted from a Python script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e0451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Magic command for matplotlib in notebooks\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08495c4f",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15e45dc",
   "metadata": {},
   "source": [
    "Define base paths, dataset locations, and result directories. **Important:** Verify and adjust `base_project_path` and `standard_imagenet_index_file_path` if necessary for your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8d6353",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_project_path = \"/home/ubuntu/project_files\"\n",
    "dataset_path = os.path.join(base_project_path, \"dataset/TestDataSet\")\n",
    "standard_imagenet_index_file_path = os.path.join(base_project_path, \"imagenet_class_index.json\")\n",
    "results_dir = os.path.join(base_project_path, \"results\")\n",
    "adv_dataset1_path = os.path.join(base_project_path, \"AdversarialTestSet1\")\n",
    "adv_dataset2_path = os.path.join(base_project_path, \"AdversarialTestSet2\") # For Task 3\n",
    "visualizations_dir_task2 = os.path.join(results_dir, \"visualizations_task2\")\n",
    "visualizations_dir_task3 = os.path.join(results_dir, \"visualizations_task3\") # For Task 3\n",
    "\n",
    "# Ensure project_files and subdirectories exist\n",
    "for path in [base_project_path, results_dir, adv_dataset1_path, adv_dataset2_path, visualizations_dir_task2, visualizations_dir_task3]:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "print(f\"Base project path: {base_project_path}\")\n",
    "print(f\"Dataset path: {dataset_path}\")\n",
    "print(f\"ImageNet index file: {standard_imagenet_index_file_path}\")\n",
    "print(f\"Results directory: {results_dir}\")\n",
    "print(\"\n",
    "Checking and creating directories...\")\n",
    "for path_to_check in [base_project_path, results_dir, adv_dataset1_path, adv_dataset2_path, visualizations_dir_task2, visualizations_dir_task3]:\n",
    "    if not os.path.exists(path_to_check):\n",
    "        os.makedirs(path_to_check, exist_ok=True)\n",
    "        print(f\"Created directory: {path_to_check}\")\n",
    "    else:\n",
    "        print(f\"Directory already exists: {path_to_check}\")\n",
    "print(\"Directory setup complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd50f1f",
   "metadata": {},
   "source": [
    "## 2. Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422a49e0",
   "metadata": {},
   "source": [
    "Utility functions for image transformations, denormalization, ImageNet class index mapping, and model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc6bc99",
   "metadata": {},
   "source": [
    "### 2.1 Normalization Constants and Device Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf434a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_norms = np.array([0.485, 0.456, 0.406])\n",
    "std_norms = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "# Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723e6b2e",
   "metadata": {},
   "source": [
    "### 2.2 Image Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb39299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plain_transforms():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean_norms, std=std_norms)\n",
    "    ])\n",
    "\n",
    "\n",
    "print(\"Helper function 'get_plain_transforms' defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f875e677",
   "metadata": {},
   "source": [
    "### 2.3 Denormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ac1141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(tensor_image):\n",
    "    img = tensor_image.clone().detach().cpu()\n",
    "    for t, m, s in zip(img, mean_norms, std_norms):\n",
    "        t.mul_(s).add_(m)\n",
    "    img = img.clamp(0, 1)\n",
    "    return transforms.ToPILImage()(img)\n",
    "\n",
    "\n",
    "print(\"Helper function 'denormalize' defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f96e2c",
   "metadata": {},
   "source": [
    "### 2.4 ImageNet Index Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee31ad76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx_to_imagenet_idx_map(current_dataset, imagenet_json_path):\n",
    "    idx_map = {}\n",
    "    try:\n",
    "        with open(imagenet_json_path, 'r') as f:\n",
    "            standard_idx_to_synset_map = json.load(f)\n",
    "        synset_to_standard_idx_map = {}\n",
    "        for std_idx_str, data_list in standard_idx_to_synset_map.items():\n",
    "            synset_id = data_list[0]\n",
    "            synset_to_standard_idx_map[synset_id] = int(std_idx_str)\n",
    "        \n",
    "        for folder_synset_id, internal_folder_idx in current_dataset.class_to_idx.items():\n",
    "            if folder_synset_id in synset_to_standard_idx_map:\n",
    "                standard_imagenet_idx = synset_to_standard_idx_map[folder_synset_id]\n",
    "                idx_map[str(internal_folder_idx)] = standard_imagenet_idx\n",
    "            else:\n",
    "                print(f\"Warning: Dataset folder synset_id {folder_synset_id} not found in standard ImageNet mapping.\")\n",
    "        \n",
    "        if not idx_map or len(idx_map) != len(current_dataset.classes):\n",
    "            print(f\"Warning: Mapping issues. Mapped {len(idx_map)} of {len(current_dataset.classes)} classes.\")\n",
    "        else:\n",
    "            print(f\"Successfully created mapping for {len(idx_map)} classes.\")\n",
    "        return idx_map\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating index map: {e}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "# Note: Ensure 'imagenet_class_index.json' is available at 'standard_imagenet_index_file_path'.\n",
    "# If not, you might need to download it. Example command (run in a separate cell if needed):\n",
    "# !mkdir -p {os.path.dirname(standard_imagenet_index_file_path)} # Ensure parent directory exists\n",
    "# !wget https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json -O {standard_imagenet_index_file_path}\n",
    "print(\"Helper function 'get_idx_to_imagenet_idx_map' defined.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6434b5be",
   "metadata": {},
   "source": [
    "### 2.5 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45691048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device, idx_to_imagenet_idx, model_name=\"Model\"):\n",
    "    model.eval()\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total_eval_samples = 0\n",
    "\n",
    "    if not idx_to_imagenet_idx:\n",
    "        print(f\"Error in evaluate_model for {model_name}: idx_to_imagenet_idx is empty.\")\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, internal_labels in dataloader:\n",
    "            inputs, internal_labels = inputs.to(device), internal_labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            _, predicted_top1_indices = torch.max(outputs, 1)\n",
    "            _, predicted_top5_indices_k = torch.topk(outputs, 5, dim=1)\n",
    "\n",
    "            for i in range(internal_labels.size(0)):\n",
    "                internal_folder_idx = internal_labels[i].item()\n",
    "                actual_target_imagenet_idx = idx_to_imagenet_idx.get(str(internal_folder_idx))\n",
    "\n",
    "                if actual_target_imagenet_idx is None:\n",
    "                    continue \n",
    "                \n",
    "                total_eval_samples +=1\n",
    "                predicted_imagenet_idx_top1 = predicted_top1_indices[i].item()\n",
    "                if predicted_imagenet_idx_top1 == actual_target_imagenet_idx:\n",
    "                    correct_top1 += 1\n",
    "                \n",
    "                predicted_imagenet_indices_top5 = predicted_top5_indices_k[i].tolist()\n",
    "                if actual_target_imagenet_idx in predicted_imagenet_indices_top5:\n",
    "                    correct_top5 += 1\n",
    "    \n",
    "    if total_eval_samples == 0:\n",
    "        print(f\"Warning for {model_name}: Total samples for evaluation was 0.\")\n",
    "        return 0.0, 0.0\n",
    "                    \n",
    "    top1_accuracy = 100 * correct_top1 / total_eval_samples\n",
    "    top5_accuracy = 100 * correct_top5 / total_eval_samples\n",
    "    print(f\"{model_name} - Top-1 Accuracy: {top1_accuracy:.2f}%, Top-5 Accuracy: {top5_accuracy:.2f}% on {total_eval_samples} samples\")\n",
    "    return top1_accuracy, top5_accuracy\n",
    "\n",
    "\n",
    "print(\"Helper function 'evaluate_model' defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0635c53",
   "metadata": {},
   "source": [
    "## 3. Task 1: Baseline Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6ac58c",
   "metadata": {},
   "source": [
    "Evaluate the pre-trained ResNet-34 model on the original (clean) TestDataSet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a94d0fa",
   "metadata": {},
   "source": [
    "### 3.1 Define `run_task1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8a7446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task1(model, device, current_dataset, idx_to_imagenet_idx):\n",
    "    print(\"\\n--- Running Task 1: Baseline Evaluation ---\")\n",
    "    dataloader = torch.utils.data.DataLoader(current_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "    top1_acc, top5_acc = evaluate_model(model, dataloader, device, idx_to_imagenet_idx, \"ResNet-34 Baseline\")\n",
    "    \n",
    "    results_file_task1 = os.path.join(results_dir, \"task1_results.txt\")\n",
    "    result_text = f\"Task 1: Baseline ResNet-34 Performance\\n\"\n",
    "    result_text += f\"Top-1 Accuracy: {top1_acc:.2f}%\\n\"\n",
    "    result_text += f\"Top-5 Accuracy: {top5_acc:.2f}%\\n\"\n",
    "    with open(results_file_task1, \"w\") as f:\n",
    "        f.write(result_text)\n",
    "    print(f\"Task 1 results saved to {results_file_task1}\")\n",
    "    return top1_acc, top5_acc\n",
    "\n",
    "\n",
    "print(\"Function \t'run_task1' defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2831511f",
   "metadata": {},
   "source": [
    "## 4. Task 2: Pixel-wise Attack (FGSM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099421e2",
   "metadata": {},
   "source": [
    "Implement the Fast Gradient Sign Method (FGSM) attack and evaluate the model's performance on the generated adversarial examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24111882",
   "metadata": {},
   "source": [
    "### 4.1 Define `fgsm_attack`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc4f0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    perturbed_image = image + epsilon * sign_data_grad\n",
    "    # The L_inf constraint is that ||perturbed_image - image||_inf <= epsilon.\n",
    "    # This is ensured by the construction if epsilon is the step size.\n",
    "    # However, to be absolutely sure and to keep image values in valid range for normalized images (approx [-2, 2]),\n",
    "    # it's good practice to clamp the *perturbation* itself to [-epsilon, epsilon] then add to original image,\n",
    "    # or clamp the final perturbed_image to [image_orig - epsilon, image_orig + epsilon].\n",
    "    # For FGSM, the formula is direct. The problem states \"L∞ distance between new and original is no greater than ε = 0.02\"\n",
    "    # This means ||x_adv - x||_inf <= eps. Our construction x_adv = x + eps * sign(grad) implies ||x_adv - x||_inf = ||eps * sign(grad)||_inf = eps * ||sign(grad)||_inf = eps * 1 = eps.\n",
    "    # So the constraint is met by definition of FGSM.\n",
    "    return perturbed_image\n",
    "\n",
    "\n",
    "print(\"Function \t'fgsm_attack' defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7dc8d8",
   "metadata": {},
   "source": [
    "### 4.2 Define `run_task2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c94b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task2(model, device, original_dataset, idx_to_imagenet_idx, epsilon=0.02):\n",
    "    print(\"\\n--- Running Task 2: FGSM Attack ---\")\n",
    "    model.eval()\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    if os.path.exists(adv_dataset1_path):\n",
    "        shutil.rmtree(adv_dataset1_path)\n",
    "    os.makedirs(adv_dataset1_path, exist_ok=True)\n",
    "\n",
    "    for class_name in original_dataset.classes:\n",
    "        os.makedirs(os.path.join(adv_dataset1_path, class_name), exist_ok=True)\n",
    "\n",
    "    num_visualized = 0\n",
    "    max_visualizations = 5\n",
    "    total_images_processed = 0\n",
    "    original_dataloader = torch.utils.data.DataLoader(original_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "    for i, (data, internal_target_idx) in enumerate(original_dataloader):\n",
    "        data, internal_target_idx = data.to(device), internal_target_idx.to(device)\n",
    "        data.requires_grad = True\n",
    "\n",
    "        output = model(data)\n",
    "        initial_pred_idx = output.max(1, keepdim=True)[1].item()\n",
    "        \n",
    "        true_imagenet_idx = idx_to_imagenet_idx.get(str(internal_target_idx.item()))\n",
    "        if true_imagenet_idx is None:\n",
    "            print(f\"Skipping image {i} in Task 2 due to missing label mapping for internal idx {internal_target_idx.item()}\")\n",
    "            continue\n",
    "        \n",
    "        target_for_loss = torch.tensor([true_imagenet_idx], device=device)\n",
    "        loss = loss_fn(output, target_for_loss)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        data_grad = data.grad.data\n",
    "\n",
    "        perturbed_data = fgsm_attack(data.detach(), epsilon, data_grad) # Detach data before modification\n",
    "\n",
    "        # Verify L-infinity distance\n",
    "        l_inf_dist_check = torch.norm(perturbed_data - data, p=float('inf')).item()\n",
    "        if l_inf_dist_check > epsilon + 1e-5: # Check with tolerance\n",
    "             print(f\"Warning Task 2: L_inf distance {l_inf_dist_check} for image {i} exceeded epsilon {epsilon}.\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output_adv = model(perturbed_data)\n",
    "        final_pred_idx = output_adv.max(1, keepdim=True)[1].item()\n",
    "\n",
    "        original_img_path, _ = original_dataset.samples[i]\n",
    "        class_name = os.path.basename(os.path.dirname(original_img_path))\n",
    "        filename = os.path.basename(original_img_path)\n",
    "        \n",
    "        adv_img_pil = denormalize(perturbed_data.squeeze(0))\n",
    "        adv_img_pil.save(os.path.join(adv_dataset1_path, class_name, filename))\n",
    "        total_images_processed += 1\n",
    "\n",
    "        if num_visualized < max_visualizations and final_pred_idx != true_imagenet_idx and initial_pred_idx == true_imagenet_idx:\n",
    "            original_pil = denormalize(data.squeeze(0).detach())\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.imshow(original_pil)\n",
    "            plt.title(f\"Original (T2): Pred {initial_pred_idx}\\nTrue: {true_imagenet_idx}\")\n",
    "            plt.axis('off')\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.imshow(adv_img_pil)\n",
    "            plt.title(f\"FGSM (eps={epsilon}): Pred {final_pred_idx}\\nTrue: {true_imagenet_idx}\")\n",
    "            plt.axis('off')\n",
    "            vis_filename = f\"fgsm_visualization_{num_visualized+1}.png\"\n",
    "            plt.savefig(os.path.join(visualizations_dir_task2, vis_filename))\n",
    "            plt.close()\n",
    "            print(f\"Saved Task 2 visualization: {vis_filename}\")\n",
    "            num_visualized += 1\n",
    "        \n",
    "        if (i+1) % 50 == 0:\n",
    "            print(f\"Processed {i+1}/{len(original_dataset)} images for FGSM attack.\")\n",
    "\n",
    "    print(f\"FGSM attack complete. {total_images_processed} adversarial images saved to {adv_dataset1_path}\")\n",
    "    adv_dataset1_eval = torchvision.datasets.ImageFolder(root=adv_dataset1_path, transform=get_plain_transforms())\n",
    "    adv_dataloader1 = torch.utils.data.DataLoader(adv_dataset1_eval, batch_size=32, shuffle=False, num_workers=0)\n",
    "    adv_idx_to_imagenet_idx1 = get_idx_to_imagenet_idx_map(adv_dataset1_eval, standard_imagenet_index_file_path)\n",
    "    \n",
    "    top1_acc_adv, top5_acc_adv = evaluate_model(model, adv_dataloader1, device, adv_idx_to_imagenet_idx1 if adv_idx_to_imagenet_idx1 else idx_to_imagenet_idx, \"ResNet-34 on AdvSet1 (FGSM)\")\n",
    "    results_file_task2 = os.path.join(results_dir, \"task2_results.txt\")\n",
    "    result_text = f\"Task 2: FGSM Attack (epsilon={epsilon}) Performance\\nTop-1 Accuracy: {top1_acc_adv:.2f}%\\nTop-5 Accuracy: {top5_acc_adv:.2f}%\\n\"\n",
    "    with open(results_file_task2, \"w\") as f: f.write(result_text)\n",
    "    print(f\"Task 2 results saved to {results_file_task2}\")\n",
    "    return top1_acc_adv, top5_acc_adv\n",
    "\n",
    "\n",
    "print(\"Function \t'run_task2' defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481820a1",
   "metadata": {},
   "source": [
    "## 5. Task 3: Improved Attack (PGD/I-FGSM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12be8fa",
   "metadata": {},
   "source": [
    "Implement the Projected Gradient Descent (PGD) attack, an iterative version of FGSM, and evaluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4361a4f8",
   "metadata": {},
   "source": [
    "### 5.1 Define `pgd_attack`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df81c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_attack(model, image_original, true_imagenet_label, epsilon, alpha, num_iter, device):\n",
    "    # PGD is an iterative version of FGSM\n",
    "    # image_original should be the original clean image, detached and requires_grad=False\n",
    "    # We create a new tensor for the adversarial image that requires grad\n",
    "    perturbed_image = image_original.clone().detach().to(device)\n",
    "    perturbed_image.requires_grad = True\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for _ in range(num_iter):\n",
    "        output = model(perturbed_image)\n",
    "        loss = loss_fn(output, torch.tensor([true_imagenet_label], device=device))\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            data_grad = perturbed_image.grad.data\n",
    "            # FGSM step\n",
    "            perturbed_image_step = perturbed_image + alpha * data_grad.sign()\n",
    "            # Project perturbation back to epsilon ball around original image\n",
    "            perturbation = torch.clamp(perturbed_image_step - image_original, -epsilon, epsilon)\n",
    "            perturbed_image = image_original + perturbation\n",
    "            # Optional: Clamp to valid image range if necessary (e.g. [0,1] for unnormalized, or model's expected normalized range)\n",
    "            # For normalized images, this usually means clamping to approx [-min_val/std, (1-min_val)/std]\n",
    "            # For now, we assume the model handles values resulting from this process.\n",
    "            # The L_inf constraint is ||perturbed_image - image_original||_inf <= epsilon, which is enforced by the clamp.\n",
    "        # perturbed_image.grad.zero_() # Zero gradients for next iteration - REMOVED TO FIX AttributeError\n",
    "        perturbed_image = perturbed_image.detach().clone() # Detach and clone for next iteration's requires_grad\n",
    "        perturbed_image.requires_grad = True\n",
    "\n",
    "    return perturbed_image.detach() # Return final detached adversarial image\n",
    "\n",
    "\n",
    "print(\"Function \t'pgd_attack' defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb49c375",
   "metadata": {},
   "source": [
    "### 5.2 Define `run_task3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a7e20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task3(model, device, original_dataset, idx_to_imagenet_idx, epsilon=0.02, alpha_factor=1.25, num_iter=10):\n",
    "    print(\"\\n--- Running Task 3: Improved Attack (PGD/I-FGSM) ---\")\n",
    "    model.eval()\n",
    "    alpha = epsilon / num_iter * alpha_factor # Step size, often a bit larger than eps/steps\n",
    "\n",
    "    if os.path.exists(adv_dataset2_path):\n",
    "        shutil.rmtree(adv_dataset2_path)\n",
    "    os.makedirs(adv_dataset2_path, exist_ok=True)\n",
    "\n",
    "    for class_name in original_dataset.classes:\n",
    "        os.makedirs(os.path.join(adv_dataset2_path, class_name), exist_ok=True)\n",
    "\n",
    "    num_visualized = 0\n",
    "    max_visualizations = 5\n",
    "    total_images_processed = 0\n",
    "    original_dataloader = torch.utils.data.DataLoader(original_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "    for i, (data_orig, internal_target_idx) in enumerate(original_dataloader):\n",
    "        data_orig = data_orig.to(device) # Original clean image, no grad needed here for PGD func\n",
    "        internal_target_idx = internal_target_idx.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output_orig = model(data_orig)\n",
    "        initial_pred_idx = output_orig.max(1, keepdim=True)[1].item()\n",
    "\n",
    "        true_imagenet_idx = idx_to_imagenet_idx.get(str(internal_target_idx.item()))\n",
    "        if true_imagenet_idx is None:\n",
    "            print(f\"Skipping image {i} in Task 3 due to missing label mapping for internal idx {internal_target_idx.item()}\")\n",
    "            continue\n",
    "\n",
    "        perturbed_data = pgd_attack(model, data_orig, true_imagenet_idx, epsilon, alpha, num_iter, device)\n",
    "        \n",
    "        # Verify L-infinity distance\n",
    "        l_inf_dist_check = torch.norm(perturbed_data - data_orig, p=float('inf')).item()\n",
    "        if l_inf_dist_check > epsilon + 1e-5: # Check with tolerance\n",
    "             print(f\"Warning Task 3: L_inf distance {l_inf_dist_check} for image {i} exceeded epsilon {epsilon}.\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output_adv = model(perturbed_data)\n",
    "        final_pred_idx = output_adv.max(1, keepdim=True)[1].item()\n",
    "\n",
    "        original_img_path, _ = original_dataset.samples[i]\n",
    "        class_name = os.path.basename(os.path.dirname(original_img_path))\n",
    "        filename = os.path.basename(original_img_path)\n",
    "        \n",
    "        adv_img_pil = denormalize(perturbed_data.squeeze(0))\n",
    "        adv_img_pil.save(os.path.join(adv_dataset2_path, class_name, filename))\n",
    "        total_images_processed += 1\n",
    "\n",
    "        if num_visualized < max_visualizations and final_pred_idx != true_imagenet_idx and initial_pred_idx == true_imagenet_idx:\n",
    "            original_pil = denormalize(data_orig.squeeze(0).detach())\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.imshow(original_pil)\n",
    "            plt.title(f\"Original (T3): Pred {initial_pred_idx}\\nTrue: {true_imagenet_idx}\")\n",
    "            plt.axis('off')\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.imshow(adv_img_pil)\n",
    "            plt.title(f\"PGD (eps={epsilon}, iter={num_iter}): Pred {final_pred_idx}\\nTrue: {true_imagenet_idx}\")\n",
    "            plt.axis('off')\n",
    "            vis_filename = f\"pgd_visualization_{num_visualized+1}.png\"\n",
    "            plt.savefig(os.path.join(visualizations_dir_task3, vis_filename))\n",
    "            plt.close()\n",
    "            print(f\"Saved Task 3 visualization: {vis_filename}\")\n",
    "            num_visualized += 1\n",
    "\n",
    "        if (i+1) % 50 == 0:\n",
    "            print(f\"Processed {i+1}/{len(original_dataset)} images for PGD attack.\")\n",
    "\n",
    "    print(f\"PGD attack complete. {total_images_processed} adversarial images saved to {adv_dataset2_path}\")\n",
    "    adv_dataset2_eval = torchvision.datasets.ImageFolder(root=adv_dataset2_path, transform=get_plain_transforms())\n",
    "    adv_dataloader2 = torch.utils.data.DataLoader(adv_dataset2_eval, batch_size=32, shuffle=False, num_workers=0)\n",
    "    adv_idx_to_imagenet_idx2 = get_idx_to_imagenet_idx_map(adv_dataset2_eval, standard_imagenet_index_file_path)\n",
    "\n",
    "    top1_acc_adv, top5_acc_adv = evaluate_model(model, adv_dataloader2, device, adv_idx_to_imagenet_idx2 if adv_idx_to_imagenet_idx2 else idx_to_imagenet_idx, \"ResNet-34 on AdvSet2 (PGD)\")\n",
    "    results_file_task3 = os.path.join(results_dir, \"task3_results.txt\")\n",
    "    result_text = f\"Task 3: Improved Attack (PGD, epsilon={epsilon}, iters={num_iter}) Performance\\nTop-1 Accuracy: {top1_acc_adv:.2f}%\\nTop-5 Accuracy: {top5_acc_adv:.2f}%\\n\"\n",
    "    with open(results_file_task3, \"w\") as f: f.write(result_text)\n",
    "    print(f\"Task 3 results saved to {results_file_task3}\")\n",
    "    return top1_acc_adv, top5_acc_adv\n",
    "\n",
    "\n",
    "print(\"Function \t'run_task3' defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cd1879",
   "metadata": {},
   "source": [
    "## 6. Main Execution / Orchestration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d8c332",
   "metadata": {},
   "source": [
    "This section provides cells to load the model, dataset, and run all tasks sequentially. Execute these cells in order. Ensure `base_project_path`, `dataset_path`, and `standard_imagenet_index_file_path` are correctly set in the Configuration section (Cell 4)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9ff776",
   "metadata": {},
   "source": [
    "### 6.1 Load Pre-trained Model and Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c41a9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Main Execution Logic ---\n",
    "print(\"Setting up device...\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(\"\n",
    "Loading pre-trained ResNet-34 model...\")\n",
    "model = torchvision.models.resnet34(weights=torchvision.models.ResNet34_Weights.IMAGENET1K_V1)\n",
    "model.to(device)\n",
    "model.eval() # Set model to evaluation mode\n",
    "print(\"ResNet-34 model loaded and moved to device.\")\n",
    "\n",
    "print(\"\n",
    "Loading original dataset...\")\n",
    "# Ensure the dataset_path points to your TestDataSet folder\n",
    "if not os.path.exists(dataset_path) or not os.listdir(dataset_path):\n",
    "    print(f\"ERROR: Original dataset not found or empty at {dataset_path}\")\n",
    "    print(\"Please ensure your TestDataSet (e.g., from ILSVRC2012 validation set, or a subset) is correctly placed.\")\n",
    "    print(\"The script expects subfolders named by synset ID (e.g., n01440764) containing images.\")\n",
    "    # Create dummy dataset and idx_map to prevent later errors if user wants to proceed partially\n",
    "    original_dataset = None\n",
    "    idx_to_imagenet_idx = {}\n",
    "else:\n",
    "    plain_transforms = get_plain_transforms()\n",
    "    original_dataset = torchvision.datasets.ImageFolder(root=dataset_path, transform=plain_transforms)\n",
    "    print(f\"Loaded {len(original_dataset)} images from {dataset_path}\")\n",
    "    print(f\"Dataset classes (folder names): {original_dataset.classes[:5]}... (first 5)\") # Show a few class names\n",
    "\n",
    "    print(\"\n",
    "Creating mapping from dataset internal indices to ImageNet indices...\")\n",
    "    idx_to_imagenet_idx = get_idx_to_imagenet_idx_map(original_dataset, standard_imagenet_index_file_path)\n",
    "    if not idx_to_imagenet_idx:\n",
    "        print(\"Warning: Index mapping failed. Evaluation results will be unreliable or zero.\")\n",
    "    else:\n",
    "        print(f\"Index mapping created for {len(idx_to_imagenet_idx)} classes.\")\n",
    "\n",
    "# Check if dataset loaded properly before proceeding\n",
    "if original_dataset and idx_to_imagenet_idx:\n",
    "    print(\"\n",
    "Model, dataset, and index mapping loaded successfully.\")\n",
    "else:\n",
    "    print(\"\n",
    "Critical error: Model, dataset, or index mapping could not be loaded. Subsequent tasks may fail or produce incorrect results.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee95362",
   "metadata": {},
   "source": [
    "### 6.2 Run Task 1: Baseline Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695aa584",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if original_dataset and idx_to_imagenet_idx:\n",
    "    print(\"\n",
    "--- Attempting to run Task 1 ---\")\n",
    "    task1_top1_acc, task1_top5_acc = run_task1(model, device, original_dataset, idx_to_imagenet_idx)\n",
    "    print(f\"Task 1 Complete. Top-1: {task1_top1_acc:.2f}%, Top-5: {task1_top5_acc:.2f}%\")\n",
    "else:\n",
    "    print(\"Skipping Task 1 due to issues with dataset loading or index mapping.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc545dfc",
   "metadata": {},
   "source": [
    "### 6.3 Run Task 2: FGSM Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499b9d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if original_dataset and idx_to_imagenet_idx:\n",
    "    print(\"\n",
    "--- Attempting to run Task 2 ---\")\n",
    "    # You can adjust epsilon here if needed\n",
    "    fgsm_epsilon = 0.02 \n",
    "    task2_top1_acc, task2_top5_acc = run_task2(model, device, original_dataset, idx_to_imagenet_idx, epsilon=fgsm_epsilon)\n",
    "    print(f\"Task 2 Complete. FGSM (eps={fgsm_epsilon}) Top-1: {task2_top1_acc:.2f}%, Top-5: {task2_top5_acc:.2f}%\")\n",
    "    print(f\"Adversarial images for Task 2 saved in: {adv_dataset1_path}\")\n",
    "    print(f\"Visualizations for Task 2 saved in: {visualizations_dir_task2}\")\n",
    "else:\n",
    "    print(\"Skipping Task 2 due to issues with dataset loading or index mapping.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546668a1",
   "metadata": {},
   "source": [
    "### 6.4 Run Task 3: PGD Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8230d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if original_dataset and idx_to_imagenet_idx:\n",
    "    print(\"\n",
    "--- Attempting to run Task 3 ---\")\n",
    "    # You can adjust PGD parameters here if needed\n",
    "    pgd_epsilon = 0.02\n",
    "    pgd_alpha_factor = 1.25 # alpha = epsilon / num_iter * alpha_factor\n",
    "    pgd_num_iter = 10\n",
    "    task3_top1_acc, task3_top5_acc = run_task3(model, device, original_dataset, idx_to_imagenet_idx, epsilon=pgd_epsilon, alpha_factor=pgd_alpha_factor, num_iter=pgd_num_iter)\n",
    "    print(f\"Task 3 Complete. PGD (eps={pgd_epsilon}, iter={pgd_num_iter}) Top-1: {task3_top1_acc:.2f}%, Top-5: {task3_top5_acc:.2f}%\")\n",
    "    print(f\"Adversarial images for Task 3 saved in: {adv_dataset2_path}\")\n",
    "    print(f\"Visualizations for Task 3 saved in: {visualizations_dir_task3}\")\n",
    "else:\n",
    "    print(\"Skipping Task 3 due to issues with dataset loading or index mapping.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
